---
title: "100 mountain"
output: html_document
---
## 本報告利用範例的爬蟲程式，在ptt Hiking版爬取30頁的討論，旨在統計跟百岳有關的討論內容 

```{r}
rm(list=ls(all.names = TRUE)) #引入需要的套件
library(NLP)
library(tm)
library(jiebaRD)
library(jiebaR)
library(RColorBrewer)
library(wordcloud)
library(ggplot2)
```
```{r}
filenames <- list.files(getwd(), pattern="*.txt") #讀取檔名中有txt 的檔案
files <- lapply(filenames, readLines, encoding="BIG5")
docs <- Corpus(VectorSource(files))
toSpace <- content_transformer(function(x, pattern) {
  return (gsub(pattern, " ", x))
}
)
```
```{r}
##篩選掉一些跟山有關但是是不想討論的廢詞
docs <- tm_map(docs, toSpace, "山上")
docs <- tm_map(docs, toSpace, "山莊")
docs <- tm_map(docs, toSpace, "山頭")
docs <- tm_map(docs, toSpace, "山林")
docs <- tm_map(docs, toSpace, "火山口")
docs <- tm_map(docs, toSpace, "高山")
docs <- tm_map(docs, toSpace, "山口")
docs <- tm_map(docs, toSpace, "山中")
docs <- tm_map(docs, toSpace, "山前")
docs <- tm_map(docs, toSpace, "山裡")
docs <- tm_map(docs, toSpace, "人山")
docs <- tm_map(docs, toSpace, "山頂")
docs <- tm_map(docs, toSpace, "巡山")
docs <- tm_map(docs, toSpace, "下山")
docs <- tm_map(docs, toSpace, "上山")
docs <- tm_map(docs, toSpace, "大山")
docs <- tm_map(docs, toSpace, "山友")
docs <- tm_map(docs, toSpace, "富士山")
docs <- tm_map(docs, toSpace, "山域")
docs <- tm_map(docs, toSpace, "嵐山")
docs <- tm_map(docs, toSpace, "爬山")
docs <- tm_map(docs, toSpace, "山屋")
docs <- tm_map(docs, toSpace, "登山")
docs <- tm_map(docs, toSpace, "山下")
docs <- tm_map(docs, toSpace, "山中湖")
docs <- tm_map(docs, toSpace, "郊山")
docs <- tm_map(docs, toSpace, "山徑")
docs <- tm_map(docs, toSpace, "入山")
docs <- tm_map(docs, toSpace, "山路")
docs <- tm_map(docs, toSpace, "登山隊")
docs <- tm_map(docs, toSpace, "山區")
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, removeNumbers)
docs <- tm_map(docs, stripWhitespace)
```
## 我自己整理了一個百岳的csv列表，目的在於讓切割詞的東東認得這些奇怪的山名

```{r}
mixseg = worker()
my.data <- read.csv("mountain.csv") #將自己整理的百岳列表讀入並作為新詞彙加入詞庫
str(my.data)
my.data$mountain <- as.character(my.data$mountain)
new_user_word(mixseg,my.data$mountain)
```
## 在下面對詞頻矩陣做了一些篩選，可能有些是多餘的但是我也懶得刪了~

```{r}
jieba_tokenizer=function(d){
  unlist(segment(d[[1]],mixseg))
}
seg = lapply(docs, jieba_tokenizer)
freqFrame <- as.data.frame(table(unlist(seg)))
freqFrame <- freqFrame[freqFrame$Freq>5,] #將詞頻矩陣中統計數量小於5或大於150的詞彙篩選掉
freqFrame <- freqFrame[freqFrame$Freq<150,]
freqFrame$Var1 <- as.character(freqFrame$Var1)
freqFrame <- freqFrame[nchar(freqFrame$Var1)>1,] #在所有字串中，自長度等於1的全部刪掉，因為長度等於1的大部分都是廢字
freqFrame <- freqFrame[grepl("山",freqFrame$Var1),] #將詞彙中有"山"的篩選出來，這樣就可以少掉很多無關的東西
freqFrame$Var1
```
## 下面畫出了柱狀圖，這個時候我發現玉山實在是太多了，這樣會導致做成文字雲的時候出現大大的玉山其他都看不太到了，所以我就去前面把玉山給篩掉

```{r}
#將詞頻矩陣畫成柱狀圖
p <- ggplot(subset(freqFrame, Freq>30 ), aes(x = reorder(Var1, -Freq), y= Freq)) +
  geom_bar(stat = "identity") +
  theme(axis.text.x=element_text(angle=45, hjust=1))
p
```

## 沒有了玉山，文字雲變得頗漂亮，而我從文字雲中得出的結論是，玉山仍是國內最受歡迎討論度最高的百岳，其次則是雪山，

```{r}
# 畫成文字雲
wordcloud(freqFrame$Var1,freqFrame$Freq,
          scale=c(7,0.1),min.freq=5,max.words=70,
          random.order=TRUE, random.color=FALSE, 
          rot.per=.1, colors=brewer.pal(8, "Dark2"),
          ordered.colors=FALSE,use.r.layout=FALSE,
          fixed.asp=TRUE)
```
